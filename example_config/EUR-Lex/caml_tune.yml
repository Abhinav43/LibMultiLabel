# data
data_dir: data/EUR-Lex
data_name: EUR-Lex
min_vocab_freq: 1
max_seq_length: 500

# train
seed: 1337
epochs: 100
batch_size: 64
optimizer: adam
learning_rate: ['choice', [0.001, 0.003, 0.0001, 0.0003]]
weight_decay: 0
patience: 5
shuffle: true

# eval
eval_batch_size: 256
monitor_metrics: ['P@1','P@3','P@5']
val_metric: P@1

# model
model_name: CAML
num_filter_per_size: ['choice', [64, 128, 256, 512]]
filter_sizes: [10]
dropout: ['choice', [0.2, 0.4, 0.6, 0.8]]
init_weight: null
activation: tanh

# pretrained vocab / embeddings
vocab_file: null
embed_file: glove.6B.300d
embed_cache_dir: .vector_cache/

# hyperparamter search
search_alg: basic_variant

# other parameters specified in main.py::get_args
config: example_config/EUR-Lex/caml_tune.yml
cpu: false
data_workers: 4
display_iter: 100
eval: false
fixed_length: false
label_file: null
load_checkpoint: null
metrics_thresholds: [0.5]
momentum: 0.9
predict_out_path: null
result_dir: runs
test_path: null
train_path: null
val_path: null
val_size: 0.2
